
\chapter{Discussion}
\label{chp:discussion}

The conclusion of this document, presented in this chapter, will
attempt to draw together concepts and lessons from previous chapters.
Included among them are salient ideas that derive from the accumulated
knowledge picked up from the experiences and research that produced
this document, known and discovered limitations of the methods
previously described, and potential avenues for future work. The
structure of this chapter is as follows: the next several sections
will touch on themes and concepts that precipitate from the earlier
technical chapters, highlighting several important lessons
learned. This will be followed by a section describing currently
understood technical limitations of the techniques presented thus far,
along with directions for future research.

\section{Themes}

\subsection{Comments on Vectorization}

Despite support for vector instructions existing in consumer grade
hardware since the late 1990's, developing applications that
successfully and efficiently use this computation model can still
present serious complications. This difficulty arises from multiple
directions, which is perhaps a reason for its continual presence. The
major challenges encountered during the work that led up to this
dissertation can be grouped into several categories: design,
abstractions, and debugging.

\paragraph{Design}~ Our experience with designing data structures and
algorithms for use with vector instructions was centered primarily
around need. While we would have preferred using existing automatic
tools and middleware that could have abstracted away the challenges of
directly writing vector-aware code, our experiences showed us that
existing solutions were unsuitable for the strict optimization and
performance requirements we operated under. We were required to
significantly restructure data structures and algorithms in order to
extract vector friendly parallelism. At present, it seems clear to us
that it remains a developer's responsibility to organize algorithms
and data structures in vector-friendly ways, such as the blocking
designs demonstrated in Chapter \ref{chp:parallelization}. And even
with these invasive restructurings, modern compilers struggle to
produce optimal vector code: minimizing the amount of register spills
into main memory, inserting appropriate prefetching instructions, and
other such optimizations can often must be completed by hand.

\paragraph{Abstractions}~ At a level higher than designing a
appropriate algorithm or data structure for vectorization, we also
were faced with the challenge of making such designs portable to
different vector architectures. Our desire to have our software be
portable to multiple platforms required us to focus on a variety of
situations, including closely related architectures, such as the
multiple vector instruction sets in the x86 family of processors, and
between architectures, such as between Intel Phi accelerator cards and
GPUs. The work demonstrated in Chapter \ref{chp:parallelization} on
the vector library class was designed to assist with this problem,
making it easier to port code between multiple vector instruction sets
in the x86 architecture family. Other related work involving
heterogeneous simulation of fluids ~\citep{LiuMAS:2016} presents an
example of the other problem, where an abstraction layer needed to be
created to communicate with Intel Phi accelerators, GPUs, and standard
CPUs on an equal basis, along with multiple implementations of the
same algorithm tailored for each architecture. It remains an open
question on how to best support such a heterogeneous architecture
environment, especially when high level abstractions can easily
prevent exploiting architecture specific properties required for
optimal performance.

\paragraph{Debugging}~ The last major issue that arose during our
development process was how to successfully debug the vectorized code we were
writing. This step proved more challenging than initially anticipated
for several, not immediately obvious, reasons. Some of the problems were
due to the structure of the code itself: By using vector instructions
we are generally breaking two commonly depended upon aspects of
code. First, a vector instruction acts upon multiple, independent
items of data at once. Because of this, identifying issues often
required tracing multiple concurrent computations at the same time, as
they are impossible to separate during execution. Second, due to the
fact that vector code is typically branch-free (or close to it), we
could not depend on tracing different code paths as a indication of
problems. Instead of being able to compartmentalize the process along
isolated branches, we were forced to look at the entire algorithm as
one continuous flow when diagnosing issues. All of these problems
would be challenging enough, but vector instructions provide one last
lingering complication during debugging. Discovered during the
creation of the vector kernels in Chapter \ref{chp:parallelization},
not all vector instruction sets, despite providing the same semantic
instructions, will the same produce bit-identical output as each other
for certain instructions. The error is generally low, small enough to
not matter in most practical scenarios, but its existence makes
checking numerical correctness difficult when exact answers cannot be
relied upon.
 
\subsection{Intuition: A Double Edged Sword}

One of the big themes in this dissertation has been the use of data
structures for non-manifold geometry. Our reasons for choosing this
family of geometry representations were primarily based on our
intuition that they would maintain many of the regularity features we
enjoyed from more strict grid-based data structures, while improving
upon the topological flexibility of those designs. For the most part,
we were satisfied in this regard - somewhat ironically, one the
biggest challenges we faced with this approach was not technical, but
our own geometric intuitions. The major problem we discovered with
non-manifold representations is that there are no real world analogs
with which we could relate to. Real objects, unlike non-manifold
geometry, can not self intersect - this is a purely non-physical
concept that makes certain algorithms easier to develop. As a result,
we struggled with these approaches as, unlike with many other topics
in visual computing, they proved to be very difficult to visualize
mentally. An example of this problem occurred during the development of
the backtracing algorithm for non-manifold level sets. Initially, due
to our intuitions at the time, we focused most of our effort on
defining the surface of the geometry and how the data structure would
capture this information. In the end, we realized that this line of
thinking, while it made sense from the perspective of visualizing our
virtual object, did not actually help us answer the real question:
where was the closest surface point. Refocused around this more
narrowly scoped goal, the backtracing algorithm described in Section
\ref{sec:levelsetalgorithms} came together much more naturally.

This problem with intuition is especially present as one transitions from two
dimensional domains into three dimensional domains. Unlike other
properties, such as those based on volume, whose complexity might only
change from a quadratic scaling to a cubic scaling, topology is much
more complex. As an example, consider the number of ways material can
be connected in a non-manifold fashion across a hexahedral cell in two
dimensions, if we think back to the idea of material continuity
described in Chapter \ref{chp:nonmanifold}. To begin, at least one of
the two shared nodes across the edge must share a material connection
- which immediately leaves the other node to either be connected or
not. If we restrict the question to representing non-overlapping
geometry and simply those objects with bifurcations not resolvable by
the grid, this leaves us with a total of two patterns: two cells
attached across an edge to a third, each containing material on only
one node, and its symmetric opposite. However, by introducing just one more
dimension, changing edges to faces, the number of possible material
patterns jumps to twenty nine symmetric pairs. The true danger is not
that the potential patterns are hard to incorporate into an algorithm,
but that a developer might miss them. The nature of these non-manifold
geometric data structures, and associated algorithms, is that they are
difficult to imagine. And what cannot be imagined is all too easy to
overlook.

\subsection{Software Engineering Lessons}

A large amount of work completed in pursuit of this dissertation was
dependent on good software engineering practices. From these
experiences, we have distilled several important ideas that are worth
further discussion. The first is a general statement on optimization
strategy. Often algorithmic optimization is judged by comparison: by
what percentage does implementation A outperform implementation B? Instead, we
find that a more absolute approach is preferable, allowing us to have
a better sense of how well our algorithms perform and, often equally
important, how much performance is being underutilized. Our approach,
given the general problem of operating over large discrete domains,
has been to consider the reading and writing of data as the primary
limiting factor in algorithmic performance. This is justified on the
following ideas: first, no work can be completed before all the inputs
have been read and all the outputs have been written, and second, we
recognize that in most modern systems have a imbalance of memory
bandwidth and computational bandwidth (one of the motivating factors
in Chapter \ref{chp:macroblocks}), making data transfer generally the
slowest component of any computation. By comparing the performance of
an implementation to the theoretical time required to move its data
set into and out of main memory\footnote{We assume, during this
  computation, that we have perfect caching of all information read,
  prefetching and other memory access optimizations. We are purely
  interested in the amount of bytes read and written, divided by the
  amount of memory bandwidth provided by the hardware platform in
  question.}, we can derive a measure of \textit{algorithmic
  efficiency}. We find this method more useful, practically, than the
common approach of comparing against existing implementations (either
ours or someone else's). By comparing against an absolute reference
point instead of a relative one, for a particular platform at least,
we had confidence that we could not do better than we had done. This
proved especially important when considering whether or not a
particular intervention was successful \textit{enough}.

Related to this approach, the next software engineering advice we have
found valuable during our work is that memory bandwidth is extremely
important and generally becomes a major consideration sooner than
people expect. This is somewhat at odds with conventional knowledge
that faster processors (i.e. improved computational bandwidth) is the
primary route to improved performance. Instead, our experiences have
shown that it is very easy to run into bottlenecks in terms of memory
transfers, even when not using vector instructions. For instance,
since memory is loaded by cache line, runs of sixty four bytes,
even scalar algorithms that load memory in unstructured ways can
suffer from poor memory bandwidth utilization. Worse, these problems
can be difficult to see - while analysis tools can report general
issues, the causes are often subtle and structural in an implementation.  

A final concept that we espouse is that understanding the particular
nature of a problem can lead to more effective solutions than existing
powerful, but generic, solutions. Our macroblock solver detailed in
Chapter \ref{chp:macroblocks} is a great example of this
philosophy. Existing algorithms for matrix reordering (which is
recognized as NP-complete), such as Minimum Degree Ordering, designed
for reducing fill-in, could not compete with our own reordering scheme
because it was tailored for the specific sparsity pattern of our
macroblocks. Similarly, despite attempting to use generic
vectorization tools and libraries initially, we found that developing
our own library, tailored for the kinds of computations we were
performing, provided more control over the final generated machine
instructions. While it might have been more expedient to use generic
solutions, our benchmark application goals required more than these
methods could provide. The trade-off between performance and
development time was judged to be worth taking.

\subsection{Domain Experiences}

The experiences of working with domain experts during the research and
development that went into the surgical simulation benchmark has left
a lasting impression and driven home several important ideas. The most
important among them is the sense that maintaining a broad attitude
when approaching new projects is beneficial and in many cases
necessary for their success. Commonly, researchers focus on narrowly
defined problems, only reluctantly moving into higher or lower levels
of abstraction. And while this focus can be desirable, potentially
leading to great advances, had we restricted our research questions to
simply pursuing theoretical improvements or algorithmic designs, we
would never have arrived at a successful tool that was both usable and
high performance. In the quest to support the needs of our domain
experts, we saw no choice but to move down the levels of abstraction
to acquire additional performance by tackling questions all the way
down to the hardware level. Likewise, as we wanted a system that was
flexible to be used in a number of real-world scenarios, we moved up
from pure simulation goals and looked at challenges in user interfaces
and network service design. Being willing to move in this space did
mean that less depth was covered, but it came at the benefit of seeing
the system from a complete perspective, allowing for cross-cutting
interventions that required a broad take on the situation. Moreover,
it was important to step outside of the field of computer science to
learn about the concepts and problems that were important in the field
of plastic surgery in order to effectively converse with our
colleagues in this domain. What resulted was a broad covering of many
areas, with perhaps less depth in any one area, which produced a
successful end product, filled with both compelling research results
and solid engineering accomplishments.

\section{Broader Applications}

Before discussing specific limitations and future work, it is worth
considering the broader applicability of the techniques described in
this dissertation to areas outside of plastic surgery
simulation. While the benchmark application discussed throughout this
document was chosen for its intrinsic challenges and potential impact
in the field of surgery, it also served as an exemplar of challenging
problems in other domains. In this section, we will look at the major
technical contributions covered in this document and how they apply to
other tasks.

The first contribution area, non-manifold embedding and level sets,
has a strong applicability elsewhere in computer graphics, including
general simulation and geometric processing. Even with nothing else
added, the ability to embed, simulate, and handle collisions between
objects in a relatively coarse grid while maintaining topological
separation of thin features is desirable. While we used these
capabilities to embed thin incisions, classic simulation problems such
as character animation and fracture modeling would all benefit from
being able to embed sub-voxel resolution material, such as fingers and
shards of a model, respectively. Another interesting area is geometric
model cleanup, where being able to construct a level set of a
self-intersecting mesh could enable mesh detangling algorithms. Other
areas where non-manifold embedding and non-manifold level sets could
be very valuable would be multiphase liquid simulations. In these
situations, multiple types of liquid need to be in very close contact
with one another. Non-manifold level sets could be used to capture
their interfaces, while still allowing multiple liquid interfaces to
exist in extremely close contact.

The next contribution, the vectorization library and related
performance optimizations, also has general applicability - here
beyond just computer graphics. While the contributions of data layout
for improving simulation performance are certainly transferable to
other deformable solid simulation tasks, such as character animation,
the core vectorization library could be applied much more broadly. The
ability to easily write and maintain vectorized numerical kernels is
valuable in any scientific or engineering effort where performance on
modern computational hardware is critical. Moreover, the work
presented in this document provides a roadmap and a list of hazards
for future developers to use when developing their own multi-threaded
and vectorized solutions. This last point should not be understated,
as we found such guidelines often absent during the development of
our solutions. Having them available to the general community is a
contribution in its own right.

Likewise, the macroblock concept and associated solver also has
applicability to general problems. These ideas were originally
designed to solve issues we were experiencing with convergence in
regions too thin ( such as the scalp area ) to handle with existing
solutions like multigrid solvers. However, as we investigated the idea
further, it became clear that the hybrid iterative-direct macroblock
solver could be used successfully on a broad collection of linear
algebra problems defined over a grid discretized domain. The type of
connectivity pattern the technique depends on is fairly common, as
grid discretized simulation and optimization problems are present in
computer graphics, mechanical engineering, additive manufacturing (3D
printing) research, and many other areas. One idea we are currently
exploring is how a macroblock style solver could be used as a drop in
replacement for existing numerical packages such as
PARDISO~\citep{pardiso-6.0a,pardiso-6.0b}, as long as the problem is
defined over a grid.

Finally, the deployment investigation has revealed several important
findings that could apply outside the scope of surgical
simulation. The major points here are the practicality of remote
simulation and the rise of web technologies as front ends for
computationally intensive tasks. While there exist open questions
concerning network bandwidth and lag, remote simulation for interactive
applications is possible - which opens up a broad range of
applications, including animation tools for the graphics
professionals, to more consumer oriented applications such as video
games and simulation assisted activities, like shopping for clothing
virtually. Building tools for these tasks can be assisted by the use
of web technologies for user interfaces and connectivity. These
frameworks, including Electron, have shown themselves to be ready to
handle complex graphics applications, including simulation, during the
trials completed as a part of this document.

In the end, we feel strongly that using a surgical simulation as the
benchmark to develop the contributions of this document was the
correct choice. It presented numerous challenges that resulted in
solutions that not only addressed the direct needs of our application,
but also applied to a broader collection of problems in computer
graphics, scientific computing, mechanical engineering, and more
consumer focused fields. Far from being limiting or restricting our
vision to a narrow problem, surgical simulation was a true springboard
to an even larger world of challenges.

\section{Limitations and Future Work}

In the remainder of this chapter, we will explore some known
limitations of the techniques presented in this document, along with
some potential places where future work could provide improvements. 

% During the development of our benchmark
% application, we needed to be aware of several important social
% concerns. These concerns range from who might be using the system to
% larger issues of general policy. At first glance, the primary users of
% a system to virtual author animations of surgical procedures would be
% surgeons and, perhaps, medical students. But these are not the only
% users we need to be concerned with. Additional important individuals
% include system and facility administrators, who will be responsible
% for maintaining and deciding the system's suitability,
% respectively. In order for a system to be successful, all of these
% people and their particular constraints need to be considered during
% the design process.

% In addition to who will be using the system, there is also
% considerable variation on how it will be used. For instance, as a
% potential training tool, do we assume that all users will be located
% in first class medical schools, all equipped with personal
% state-of-the-art workstations with which to run high quality
% simulations? Or would our system be used by smaller schools in
% developing countries, where getting expert instruction and learning
% materials virtually might be very attractive? In reality, the
% situation is probably somewhere on the spectrum between these
% two. Availability of local computational resources, expert
% instructors, and the number of students will all vary. As such, our
% deployment efforts should be aware of these potential use cases.

% At a larger scale, an important policy concern is privacy. Modern medical
% practices work with intensely private data belonging to patients on a
% daily basis. The risks with this data being leaked to the general
% public are so severe that many countries have strict laws describing
% how this data can be handled and transmitted. In the United States,
% these rules are described by HIPAA (Health Insurance Portability and
% Accountability Act). While it is beyond the scope of this document to
% discuss the intricacies of these rules and software design, when we
% consider deploying surgical simulators, which might be used with
% actual patient data, we should keep HIPAA (and similar statutes) in mind.
\subsection{Non-manifold Level sets}

Our pipeline for non-manifold level sets in Chapter
\ref{chp:nonmanifold} was been specifically created for self-collision
processing in deformable body simulations. There are several diverse
applications of the standard (manifold) level set concept such as
representing geometry, tracking dynamically evolving interfaces, as a
geometric query structure, etc. However, we believe that the current
methodology may require application-specific embellishments to cater
to broader tasks in modeling and simulation, beyond what was needed
for our collision-oriented proof of concept.  For example, when two
dynamically evolving interfaces are brought together, they may either
be allowed to merge (as is typical in fluid simulations) or overtake
one another (e.g.\ the two separate branches of the lips during
self-collision). Thus, application-specific semantics might be needed
to use non-manifold level sets for dynamic interfaces.  Finally, we
showed two examples (Figures \ref{fig:zplasty-and-net} and
\ref{fig:zero-width}) where the simulated elastic model resulted from
conceptual ``cutting'' operations; in both cases we simply generated
the non-manifold level set from the final, cut geometry. If such cuts
were progressively enacted during simulation, our present
implementation would sustain a significant recompuation cost to
rebuild the non-manifold implicit representation. Incremental update
following localized topology change will be a significant direction of
future investigation.

Currently, we do not extend the non-manifold level set values into a
narrow band outside the interface because we used the same grid both
for simulation and for storing level set values. If the extent is
predetermined, then we could generate a coarse non-manifold level set
mesh first and refine it as a post-process. Alternatively, one could
also ``grow'' the non-manifold level set by following characteristics,
but as mentioned above, one may or may not wish to merge overlapping
characteristics depending on the context. This issue is also related
to the question of ``evolving'' a non-manifold level set.  In future
work, we wish to address these questions targeting the specific
applications of multiphase flow and crack propagation.  For standard
Cartesian grid-based level sets, there exists an established
theoretical foundation for accurately computing high order gradients
even in the vicinity of singularities. For non-manifold level sets, an
extra level of complexity is introduced because there can be a
topological bifurcation in addition to a singularity.  To obtain valid
values in such complex situations, our current scheme reverts to first
order element-wise trilinear interpolation.  It would be interesting
to explore in future work if there can be a more accurate
representation for the interface in these cases.  In all of our
examples we generated the non-manifold level set at the same
resolution as the underlying lattice-based elasticity
discretization. This was motivated by the fact that the ability of the
elastic model to respond to collision events is restricted by the
resolution of the elastic model, limiting the hazards of interpolation
errors near high-curvature areas.  Although this has been a successful
heuristic for our test cases, there is no guarantee that such
resolution will always be accurate for proper collision detection and
response. A higher resolution can be used for the level set, if
desired; doubling the linear resolution, for example, would incur an
8x increase in level set construction, but no worse than a two-fold
increase of the backtrace cost, in practice (assuming collisions
remain relatively shallow).

Finally, the current implementation used Cartesian grids as template
meshes for generating the non-manifold level set. In future work, an
exploration of different representations such as
octrees~\citep{LosasGF:2004}, RLE
representations~\citep{HoustNBNM:2006,IrvinGLF:2006,ChentM:2011}, the
VDB data structure~\citep{Muset:2013} and SPGrid~\citep{SetalABS:2014}
would be warranted.

\subsection{Performance Optimization and Macroblocks}

In Chapters \ref{chp:parallelization} and \ref{chp:macroblocks}, we
looked at two different approaches for improving the performance of
computing forces and solving elastic deformation problems. To some
extent, the two approaches are the result of sequential
development. While the blocking organization allowed us to compute
forces for elasticity problems very efficiently, we found that the
addition of large numbers of force constraints and complex materials,
like muscle fibers, negatively impacted our ability to achieve
reasonable convergence with Conjugate Gradients, the iterative solver
we used for the surgery simulation prototype. At the time, this
was not a large problem, as we used the partially converged steps of
the simulation as an approximation of dynamics. Moreover, the
relatively rapid CG iterations allowed us to present more visual
updates to users, giving the platform a more responsive
feel. Nevertheless, we were hoping to improve upon the poor
convergence we were seeing, a quest which ultimately led us to the
macroblock idea. Unfortunately, despite achieving the goal of better
convergence and a better ratio of memory to computational resources,
this technique fell short in several important areas.

The most important limitations of our macroblock formulation are (a)
the restriction of our scheme to Cartesian lattice-based
discretizations of elasticity, and (b) the explicit lack of support
for self collisions or other elastic interactions that would couple
together disjoint parts of the mesh. We consciously limited our
preliminary exploration to applications of macroblocks within a
Newton-Raphson iterative solution scheme. In principle, there would
have been an opportunity to also consider using macroblocks in the
design of a highly efficient box smoother for multigrid, or as a
replacement of the local optimization step in projective dynamics; we
defer exploration of those interesting threads to future work. In
terms of practical performance, the macroblock technique also includes
an expensive factorization step. While this process should be
vectorizable, and thereby mitigating this cost somewhat, it remains a
significant bottleneck for interactive use cases at the moment. It is
this issue, along with the lack of self collision support, which has
prevented it from being included in the current iterations of the
plastic surgery simulation tool.

\subsection{Surgery Simulation Platform}

As was mentioned in Chapter \ref{chp:deployment}, the feature set of
the surgical tool was relatively modest. These limitations were a
conscious choice to allow us to focus on the platform itself,
balancing performance and extensibility. From a research standpoint,
our biggest perceived challenge is improving the accuracy of the
constitutive models for the biomaterials involved. At the time of the
pilot deployment described in Section \ref{sec:pilot}, full
self-collision support as per the work described in Chapter
\ref{chp:nonmanifold} had not been integrated into the benchmark, but
this support will be essential for extending our work to procedures
that rely on contact, in addition to sutures, to model
properly. Finally, a large class of reconstructive procedures cannot
be modeled with all incisions performed at the beginning of time; a
flexible topology change modeling system would be necessary to
incorporate a seamless ability for topology change, concurrent with
deformation.

In terms of technical feasibility, while we did not experience any
major technical difficulties during the pilot deployment, the setup
environment used was near optimal. Future testing and development will
need to focus on robustness to less ideal settings. Some issues that
will need to be addressed are improved handling of networks with
variable latency and packet loss, protocol bandwidth usage, and
general scalability beyond the eight stations used in the pilot
deployment. While these are certainly major challenges, we feel they
are well within our grasp as they have similarities with other fields
such as multiplayer video games and media streaming. 

A final note concerns an issue surrounding deployment: maintaining
medical privacy. While supporting a surgical simulation tool that
allows for remote collaboration might be extremely helpful, it is
important to keep in mind the implication of medical privacy
regulations, such as the HIPPA (Health Insurance Portability and
Accountability Act) laws in the United States. Maintaining compliance
with these regulations while still being able to transmit potentially
patient specific pathology data to remote servers will be challenging
to reconcile. There are interesting open questions about how this
might be performed, given that the simulation requires access to the
geometry of the model being simulated. One saving grace of our system is that the
simulations are executed on an embedding lattice, which is only an
approximation of a patient's tissue geometry. One might imagine a
protocol that kept the actual geometry being manipulated local and
transmitted some kind of obfuscated representation for remote
computation. Or with potentially a dual simulation design, where the
remote server would compute bulk updates on a generic tissue model and
the local client would use these updates as a highly effective
preconditioner for a higher detail, patient specific model. These are
questions than should receive more attention before these systems are
ready for production use.





%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../document"
%%% End:
